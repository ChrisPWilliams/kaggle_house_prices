{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9da8329",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-07-24T11:50:44.710752Z",
     "iopub.status.busy": "2022-07-24T11:50:44.709601Z",
     "iopub.status.idle": "2022-07-24T11:50:44.722378Z",
     "shell.execute_reply": "2022-07-24T11:50:44.721675Z"
    },
    "papermill": {
     "duration": 0.022193,
     "end_time": "2022-07-24T11:50:44.725067",
     "exception": false,
     "start_time": "2022-07-24T11:50:44.702874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/house-prices-advanced-regression-techniques/sample_submission.csv\n",
      "/kaggle/input/house-prices-advanced-regression-techniques/data_description.txt\n",
      "/kaggle/input/house-prices-advanced-regression-techniques/train.csv\n",
      "/kaggle/input/house-prices-advanced-regression-techniques/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "376dee31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T11:50:44.735893Z",
     "iopub.status.busy": "2022-07-24T11:50:44.735319Z",
     "iopub.status.idle": "2022-07-24T11:50:53.287850Z",
     "shell.execute_reply": "2022-07-24T11:50:53.286585Z"
    },
    "papermill": {
     "duration": 8.560022,
     "end_time": "2022-07-24T11:50:53.290217",
     "exception": false,
     "start_time": "2022-07-24T11:50:44.730195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1456</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1457</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1458</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1459</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1460</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "1455  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1456  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1457  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities  ... ScreenPorch PoolArea PoolQC  Fence  \\\n",
       "0            Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "1            Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "2            Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "3            Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "4            Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "...          ...       ...  ...         ...      ...    ...    ...   \n",
       "1455         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "1456         Lvl    AllPub  ...           0        0    NaN  MnPrv   \n",
       "1457         Lvl    AllPub  ...           0        0    NaN  GdPrv   \n",
       "1458         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "1459         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "\n",
       "     MiscFeature MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
       "0            NaN       0      2    2008        WD         Normal  \n",
       "1            NaN       0      5    2007        WD         Normal  \n",
       "2            NaN       0      9    2008        WD         Normal  \n",
       "3            NaN       0      2    2006        WD        Abnorml  \n",
       "4            NaN       0     12    2008        WD         Normal  \n",
       "...          ...     ...    ...     ...       ...            ...  \n",
       "1455         NaN       0      8    2007        WD         Normal  \n",
       "1456         NaN       0      2    2010        WD         Normal  \n",
       "1457        Shed    2500      5    2010        WD         Normal  \n",
       "1458         NaN       0      4    2010        WD         Normal  \n",
       "1459         NaN       0      6    2008        WD         Normal  \n",
       "\n",
       "[1460 rows x 80 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "house_data = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/train.csv\")\n",
    "train_labels = house_data[\"SalePrice\"].copy()\n",
    "train_data = house_data.copy()\n",
    "train_data.drop(columns=\"SalePrice\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b3092d",
   "metadata": {
    "papermill": {
     "duration": 0.004022,
     "end_time": "2022-07-24T11:50:53.298776",
     "exception": false,
     "start_time": "2022-07-24T11:50:53.294754",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Columns contain mixture of categorical data and numerical data, these will require different preprocessing. We have:\n",
    "* Numerical data: This needs to be scaled between 0 and 1.\n",
    "* Categorical data (including the zoning code!): This needs to be one-hot encoded.\n",
    "* 'Quality' categories: This needs to be converted to an equal numeric range between 0 and 1.\n",
    "\n",
    "Missing values must also be managed:\n",
    "* For numerical columns, exclude all NA rows to find the mean, then replace NA with the mean wherever it appears\n",
    "* For categorical columns, NA will be included as a category\n",
    "* Neither the training data nor test data contains any nulls (but if they were there then they should be replaced with NA first, then subjected to the same processing.\n",
    "\n",
    "All these steps must be performed on the training data and validation data separately after splitting them! (wrap in function to take each) otherwise replacement with the mean of the whole dataset would lead to information leakage between train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6f8e25b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T11:50:53.309101Z",
     "iopub.status.busy": "2022-07-24T11:50:53.308338Z",
     "iopub.status.idle": "2022-07-24T11:50:53.320327Z",
     "shell.execute_reply": "2022-07-24T11:50:53.319544Z"
    },
    "papermill": {
     "duration": 0.019509,
     "end_time": "2022-07-24T11:50:53.322449",
     "exception": false,
     "start_time": "2022-07-24T11:50:53.302940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def quality_preprocess(data):\n",
    "    lotshapeencode = {\"Reg\":0, \"IR1\":1, \"IR2\":2, \"IR3\":3}\n",
    "    data[\"LotShape\"] = data[\"LotShape\"].replace(lotshapeencode)\n",
    "    landslopeencode = {\"Gtl\":0, \"Mod\":1, \"Sev\":2}\n",
    "    data[\"LandSlope\"] = data[\"LandSlope\"].replace(landslopeencode)\n",
    "    qualcondencode = {\"Ex\":5, \"Gd\":4, \"TA\":3, \"Fa\":2, \"Po\":1, \"NA\":0}\n",
    "    data[\"ExterQual\"] = data[\"ExterQual\"].replace(qualcondencode)\n",
    "    data[\"ExterCond\"] = data[\"ExterCond\"].replace(qualcondencode)\n",
    "    data[\"BsmtQual\"] = data[\"BsmtQual\"].replace(qualcondencode)\n",
    "    data[\"BsmtCond\"] = data[\"BsmtCond\"].replace(qualcondencode)\n",
    "    exposureencode = {\"Gd\":3, \"Av\":2, \"Mn\":1, \"No\":0}\n",
    "    data[\"BsmtExposure\"] = data[\"BsmtExposure\"].replace(exposureencode)\n",
    "    data[\"HeatingQC\"] = data[\"HeatingQC\"].replace(qualcondencode)\n",
    "    data[\"KitchenQual\"] = data[\"KitchenQual\"].replace(qualcondencode)\n",
    "    functionalencode = {\"Typ\":7, \"Min1\":6, \"Min2\":5, \"Mod\":4, \"Maj1\":3, \"Maj2\":2, \"Sev\":1, \"Sal\":0}\n",
    "    data[\"Functional\"] = data[\"Functional\"].replace(functionalencode)\n",
    "    data[\"FireplaceQu\"] = data[\"FireplaceQu\"].replace(qualcondencode)\n",
    "    finishencode = {\"Fin\":2, \"RFn\":1, \"Unf\":0}\n",
    "    data[\"GarageFinish\"] = data[\"GarageFinish\"].replace(finishencode)\n",
    "    data[\"GarageQual\"] = data[\"GarageQual\"].replace(qualcondencode)\n",
    "    data[\"GarageCond\"] = data[\"GarageCond\"].replace(qualcondencode)\n",
    "    poolencode = {\"Ex\":4, \"Gd\":3, \"TA\":2, \"Fa\":1, \"NA\":0}\n",
    "    data[\"PoolQC\"] = data[\"PoolQC\"].replace(poolencode)\n",
    "    fenceencode = {\"GdPrv\":4, \"MnPrv\":3, \"GdWo\":2, \"MnWw\":1, \"NA\":0}\n",
    "    data[\"Fence\"] = data[\"Fence\"].replace(fenceencode)\n",
    "    data[\"DateSold\"] = data[\"YrSold\"] + (data[\"MoSold\"] / 12)\n",
    "    data.drop(columns=[\"YrSold\", \"MoSold\"])\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf399881",
   "metadata": {
    "papermill": {
     "duration": 0.003925,
     "end_time": "2022-07-24T11:50:53.330627",
     "exception": false,
     "start_time": "2022-07-24T11:50:53.326702",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Define which columns should be categorical, and which should be numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccc133e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T11:50:53.340545Z",
     "iopub.status.busy": "2022-07-24T11:50:53.339918Z",
     "iopub.status.idle": "2022-07-24T11:50:53.348078Z",
     "shell.execute_reply": "2022-07-24T11:50:53.347361Z"
    },
    "papermill": {
     "duration": 0.015437,
     "end_time": "2022-07-24T11:50:53.350043",
     "exception": false,
     "start_time": "2022-07-24T11:50:53.334606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "categorical_features = [\n",
    "    \"MSSubClass\",\n",
    "    \"MSZoning\",\n",
    "    \"Street\",\n",
    "    \"Alley\",\n",
    "    \"LandContour\",\n",
    "    \"Utilities\",\n",
    "    \"LotConfig\",\n",
    "    \"Neighborhood\",\n",
    "    \"Condition1\",\n",
    "    \"Condition2\",\n",
    "    \"BldgType\",\n",
    "    \"HouseStyle\",\n",
    "    \"RoofStyle\",\n",
    "    \"RoofMatl\",\n",
    "    \"Exterior1st\",\n",
    "    \"Exterior2nd\",\n",
    "    \"MasVnrType\",\n",
    "    \"Foundation\",\n",
    "    \"BsmtFinType1\",\n",
    "    \"BsmtFinType2\",\n",
    "    \"Heating\",\n",
    "    \"CentralAir\",\n",
    "    \"Electrical\",\n",
    "    \"GarageType\",\n",
    "    \"PavedDrive\",\n",
    "    \"MiscFeature\",\n",
    "    \"SaleType\",\n",
    "    \"SaleCondition\"\n",
    "]\n",
    "\n",
    "numerical_features = [\n",
    "    \"LotFrontage\",\n",
    "    \"LotArea\",\n",
    "    \"LotShape\",\n",
    "    \"LandSlope\",\n",
    "    \"OverallQual\",\n",
    "    \"OverallCond\",\n",
    "    \"YearBuilt\",\n",
    "    \"YearRemodAdd\",\n",
    "    \"MasVnrArea\",\n",
    "    \"ExterQual\",\n",
    "    \"ExterCond\",\n",
    "    \"BsmtQual\",\n",
    "    \"BsmtCond\",\n",
    "    \"BsmtExposure\",\n",
    "    \"BsmtFinSF1\",\n",
    "    \"BsmtFinSF2\",\n",
    "    \"BsmtUnfSF\",\n",
    "    \"TotalBsmtSF\",\n",
    "    \"HeatingQC\",\n",
    "    \"1stFlrSF\",\n",
    "    \"2ndFlrSF\",\n",
    "    \"LowQualFinSF\",\n",
    "    \"GrLivArea\",\n",
    "    \"BsmtFullBath\",\n",
    "    \"BsmtHalfBath\",\n",
    "    \"FullBath\",\n",
    "    \"HalfBath\",\n",
    "    \"BedroomAbvGr\",\n",
    "    \"KitchenAbvGr\",\n",
    "    \"KitchenQual\",\n",
    "    \"TotRmsAbvGrd\",\n",
    "    \"Functional\",\n",
    "    \"Fireplaces\",\n",
    "    \"FireplaceQu\",\n",
    "    \"GarageYrBlt\",\n",
    "    \"GarageFinish\",\n",
    "    \"GarageCars\",\n",
    "    \"GarageArea\",\n",
    "    \"GarageQual\",\n",
    "    \"GarageCond\",\n",
    "    \"WoodDeckSF\",\n",
    "    \"OpenPorchSF\",\n",
    "    \"EnclosedPorch\",\n",
    "    \"3SsnPorch\",\n",
    "    \"ScreenPorch\",\n",
    "    \"PoolArea\",\n",
    "    \"PoolQC\",\n",
    "    \"Fence\",\n",
    "    \"MiscVal\",\n",
    "    \"DateSold\"\n",
    "]\n",
    "\n",
    "assert len(categorical_features) + len(numerical_features) == 78"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f037aa6",
   "metadata": {
    "papermill": {
     "duration": 0.00384,
     "end_time": "2022-07-24T11:50:53.358108",
     "exception": false,
     "start_time": "2022-07-24T11:50:53.354268",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Write preprocess instructions for categorical features, and loop for numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a59a6726",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T11:50:53.368010Z",
     "iopub.status.busy": "2022-07-24T11:50:53.367662Z",
     "iopub.status.idle": "2022-07-24T11:50:53.390013Z",
     "shell.execute_reply": "2022-07-24T11:50:53.388827Z"
    },
    "papermill": {
     "duration": 0.029821,
     "end_time": "2022-07-24T11:50:53.391991",
     "exception": false,
     "start_time": "2022-07-24T11:50:53.362170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def one_hot_feature(data, feature, featlist):\n",
    "    if feature in data:\n",
    "        one_hot = pd.get_dummies(data[feature])\n",
    "        for feat in featlist:\n",
    "            if feat not in one_hot.keys():\n",
    "                one_hot[feat] = 0\n",
    "        newnames = []\n",
    "        for feat in featlist:\n",
    "            newname = feature + '.' + feat\n",
    "            newnames.append(newname)\n",
    "        rename_dict = dict(zip(featlist, newnames))\n",
    "        one_hot = one_hot.rename(columns = rename_dict)\n",
    "        data = data.drop(columns = feature)\n",
    "        data = data.join(one_hot)\n",
    "    return data\n",
    "\n",
    "def categorical_preprocess(data):\n",
    "    subclasslist = [\"20\",\"30\",\"40\",\"45\",\"50\",\"60\",\"70\",\"75\",\"80\",\"85\",\"90\",\"120\",\"150\",\"160\",\"180\",\"190\"]\n",
    "    data = one_hot_feature(data, \"MSSubClass\", subclasslist)\n",
    "    zoninglist = ['A', 'C (all)','FV','I','RH','RL','RP','RM']\n",
    "    data = one_hot_feature(data, \"MSZoning\", zoninglist)\n",
    "    streetlist = ['Grvl','Pave']\n",
    "    data = one_hot_feature(data, \"Street\", streetlist)\n",
    "    alleylist = ['Grvl','Pave','NA']\n",
    "    data = one_hot_feature(data, \"Alley\", alleylist)\n",
    "    contourlist = ['Lvl','Bnk','HLS','Low']\n",
    "    data = one_hot_feature(data, \"LandContour\", contourlist)\n",
    "    utilitieslist = ['AllPub', 'NoSewr', 'NoSeWa', 'ELO']\n",
    "    data = one_hot_feature(data, \"Utilities\", utilitieslist)\n",
    "    lotconfiglist = ['Inside','Corner','CulDSac','FR2','FR3']\n",
    "    data = one_hot_feature(data, \"LotConfig\", lotconfiglist)\n",
    "    neighborhoodlist = [\n",
    "        'Blmngtn',\n",
    "        'Blueste',\n",
    "        'BrDale',\n",
    "        'BrkSide',\n",
    "        'ClearCr',\n",
    "        'CollgCr',\n",
    "        'Crawfor',\n",
    "        'Edwards',\n",
    "        'Gilbert',\n",
    "        'IDOTRR',\n",
    "        'MeadowV',\n",
    "        'Mitchel',\n",
    "        'Names',\n",
    "        'NoRidge',\n",
    "        'NPkVill',\n",
    "        'NridgHt',\n",
    "        'NWAmes',\n",
    "        'OldTown',\n",
    "        'SWISU',\n",
    "        'Sawyer',\n",
    "        'SawyerW',\n",
    "        'Somerst',\n",
    "        'StoneBr',\n",
    "        'Timber',\n",
    "        'Veenker'\n",
    "    ]\n",
    "    data = one_hot_feature(data, \"Neighborhood\", neighborhoodlist)\n",
    "    conditionlist = ['Artery','Feedr','Norm','RRNn','RRAn','PosN','PosA','RRNe','RRAe']\n",
    "    data = one_hot_feature(data, \"Condition1\", conditionlist)\n",
    "    data = one_hot_feature(data, \"Condition2\", conditionlist)\n",
    "    bldgtypelist = ['1Fam','2FmCon','Duplx','TwnhsE','TwnhsI']\n",
    "    data = one_hot_feature(data, \"BldgType\", bldgtypelist)\n",
    "    housestylelist = ['1Story','1.5Fin','1.5Unf','2Story','2.5Fin','2.5Unf','SFoyer','SLvl']\n",
    "    data = one_hot_feature(data, \"HouseStyle\", housestylelist)\n",
    "    roofstylelist = ['Flat','Gable','Gambrel','Hip','Mansard','Shed']\n",
    "    data = one_hot_feature(data, \"RoofStyle\", roofstylelist)\n",
    "    roofmatllist = ['ClyTile','CompShg','Membran','Metal','Roll','Tar&Grv','WdShake','WdShngl']\n",
    "    data = one_hot_feature(data, \"RoofMatl\", roofmatllist)\n",
    "    exteriorlist = [\n",
    "        'AsbShng',\n",
    "        'AsphShn',\n",
    "        'BrkFace',\n",
    "        'BrkComm',\n",
    "        'CBlock',\n",
    "        'CemntBd',\n",
    "        'HdBoard',\n",
    "        'ImStucc',\n",
    "        'MetalSd',\n",
    "        'Other',\n",
    "        'Plywood',\n",
    "        'PreCast',\n",
    "        'Stone',\n",
    "        'Stucco',\n",
    "        'VinylSd',\n",
    "        'Wd Sdng',\n",
    "        'WdShing'\n",
    "    ]\n",
    "    data = one_hot_feature(data, \"Exterior1st\", exteriorlist)\n",
    "    data = one_hot_feature(data, \"Exterior2nd\", exteriorlist)\n",
    "    masvnrtypelist = ['BrkCmn','BrkFace','CBlock','None','Stone']\n",
    "    data = one_hot_feature(data, \"MasVnrType\", masvnrtypelist)\n",
    "    foundationlist = [\"BrkTil\",'Cblock','PConc','Slab','Stone','Wood']\n",
    "    data = one_hot_feature(data, \"Foundation\", foundationlist)\n",
    "    bsmtfinlist = ['GLQ','ALQ','BLQ','Rec','LwQ','Unf','NA']\n",
    "    data = one_hot_feature(data, \"BsmtFinType1\", bsmtfinlist)\n",
    "    data = one_hot_feature(data, \"BsmtFinType2\", bsmtfinlist)\n",
    "    heatinglist = ['Floor','GasA','GasW','Grav','OthW','Wall']\n",
    "    data = one_hot_feature(data, \"Heating\", heatinglist)\n",
    "    centralairlist = ['N','Y']\n",
    "    data = one_hot_feature(data, \"CentralAir\", centralairlist)\n",
    "    electricallist = ['SBrkr','FuseA','FuseF','FuseP','Mix']\n",
    "    data = one_hot_feature(data, \"Electrical\", electricallist)\n",
    "    garagelist = ['2Types','Attchd','Basement','BuiltIn','CarPort','Detchd','NA']\n",
    "    data = one_hot_feature(data, \"GarageType\", garagelist)\n",
    "    paveddrivelist = ['Y','N','P']\n",
    "    data = one_hot_feature(data, \"PavedDrive\", paveddrivelist)\n",
    "    misclist = ['Elev','Gar2','Othr','Shed','TenC','NA']\n",
    "    data = one_hot_feature(data, \"MiscFeature\", misclist)\n",
    "    saletypelist = ['WD','CWD','VWD','New','COD','Con','ConLw','ConLI','ConLD','Oth']\n",
    "    data = one_hot_feature(data, \"SaleType\", saletypelist)\n",
    "    saleconditionlist = ['Normal','Abnorml','AdjLand','Alloca','Family','Partial']\n",
    "    data = one_hot_feature(data, \"SaleCondition\", saleconditionlist)\n",
    "    return data\n",
    "\n",
    "def normalise_preprocess(data):\n",
    "    for feature in numerical_features:\n",
    "        data[feature] = data[feature].replace({\"NA\":pd.NA})\n",
    "        mean = data[feature].mean()\n",
    "        data[feature] = data[feature].fillna(mean)\n",
    "        stddev = data[feature].std()\n",
    "        data[feature] = data[feature].sub(mean)\n",
    "        data[feature] = data[feature].div(stddev)\n",
    "    data = data.astype(\"float64\")\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5db5e0d",
   "metadata": {
    "papermill": {
     "duration": 0.003934,
     "end_time": "2022-07-24T11:50:53.400173",
     "exception": false,
     "start_time": "2022-07-24T11:50:53.396239",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Features must be tested for relevance: numerical data must be tested by pearson coefficient (pandas df.corr(method='pearson')), ordinal categorical data (which will be numbers) tested by spearman's rank coefficient (pandas df.corr(method='spearman'))\n",
    "\n",
    "non-ordered categorical data will be tested by stdev of means / mean of stdevs of the sale price for each category in the field (unless i can find a better clustering metric on the internet)\n",
    "if that doesn't work, then after one-hot encoding i will just find the stddev of the sales inside the category and divide the stddev of the whole set by that to drop individual one-hot encodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4324e1ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T11:50:53.410745Z",
     "iopub.status.busy": "2022-07-24T11:50:53.409767Z",
     "iopub.status.idle": "2022-07-24T11:50:54.326218Z",
     "shell.execute_reply": "2022-07-24T11:50:54.325199Z"
    },
    "papermill": {
     "duration": 0.924229,
     "end_time": "2022-07-24T11:50:54.328564",
     "exception": false,
     "start_time": "2022-07-24T11:50:53.404335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "house_data = quality_preprocess(house_data)\n",
    "\n",
    "catcoeffs = {}\n",
    "for feature in categorical_features:\n",
    "    categories = house_data[feature].unique()\n",
    "    catlist = categories.tolist()\n",
    "    catmeans = []\n",
    "    catdevs = []\n",
    "    for category in catlist:\n",
    "        cluster_data = house_data[[feature, \"SalePrice\"]].loc[house_data[feature] == category]\n",
    "        catmeans.append(cluster_data[\"SalePrice\"].mean())\n",
    "        catdevs.append(cluster_data[\"SalePrice\"].std())\n",
    "    devofmeans = pd.DataFrame(catmeans).std()\n",
    "    meanofdevs = pd.DataFrame(catdevs).mean()\n",
    "    catcoeffs[feature] = devofmeans[0] / meanofdevs[0]\n",
    "\n",
    "ordinal_features = [\n",
    "    \"LotShape\",\n",
    "    \"LandSlope\",\n",
    "    \"OverallQual\",\n",
    "    \"OverallCond\",\n",
    "    \"YearBuilt\",\n",
    "    \"YearRemodAdd\",\n",
    "    \"ExterQual\",\n",
    "    \"ExterCond\",\n",
    "    \"BsmtQual\",\n",
    "    \"BsmtCond\",\n",
    "    \"BsmtExposure\",\n",
    "    \"HeatingQC\",\n",
    "    \"BsmtFullBath\",\n",
    "    \"BsmtHalfBath\",\n",
    "    \"FullBath\",\n",
    "    \"HalfBath\",\n",
    "    \"BedroomAbvGr\",\n",
    "    \"KitchenAbvGr\",\n",
    "    \"KitchenQual\",\n",
    "    \"TotRmsAbvGrd\",\n",
    "    \"Functional\",\n",
    "    \"Fireplaces\",\n",
    "    \"FireplaceQu\",\n",
    "    \"GarageYrBlt\",\n",
    "    \"GarageFinish\",\n",
    "    \"GarageCars\",\n",
    "    \"GarageQual\",\n",
    "    \"GarageCond\",\n",
    "    \"Fence\",\n",
    "    \"MiscVal\",\n",
    "    \"PoolQC\"\n",
    "]\n",
    "\n",
    "non_ordinal_features = []\n",
    "\n",
    "for feature in numerical_features:\n",
    "    if feature not in ordinal_features:\n",
    "        non_ordinal_features.append(feature)\n",
    "\n",
    "for feature in ordinal_features:\n",
    "    assert feature not in categorical_features\n",
    "\n",
    "numcoeffs = {}\n",
    "for feature in numerical_features:\n",
    "    if feature in ordinal_features:\n",
    "        numcoeffs[feature] = abs(house_data[feature].corr(house_data[\"SalePrice\"], method=\"spearman\"))\n",
    "    else:\n",
    "        numcoeffs[feature] = abs(house_data[feature].corr(house_data[\"SalePrice\"], method=\"pearson\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6750fc45",
   "metadata": {
    "papermill": {
     "duration": 0.004098,
     "end_time": "2022-07-24T11:50:54.337155",
     "exception": false,
     "start_time": "2022-07-24T11:50:54.333057",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Remove features with weak correlation if needed\n",
    "\n",
    "PoolQC and PoolArea destabilise the model: this is because they are numerical but are mostly zeros/NaNs so the normalisation process doesn't work properly if either the train set or validation set only includes zeros/NaNs. filter these out by checking for a large modal value (which because they're continuous must be zero or NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f662524",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T11:50:54.347847Z",
     "iopub.status.busy": "2022-07-24T11:50:54.346923Z",
     "iopub.status.idle": "2022-07-24T11:50:54.798705Z",
     "shell.execute_reply": "2022-07-24T11:50:54.797157Z"
    },
    "papermill": {
     "duration": 0.459564,
     "end_time": "2022-07-24T11:50:54.801088",
     "exception": false,
     "start_time": "2022-07-24T11:50:54.341524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed the following features: ['Id', 'PoolArea', 'PoolQC']\n"
     ]
    }
   ],
   "source": [
    "CATTHRESHOLD = 0\n",
    "NUMTHRESHOLD = 0\n",
    "\n",
    "trash_feats = [\"Id\"]\n",
    "for feature in categorical_features:\n",
    "    if catcoeffs[feature] < CATTHRESHOLD:\n",
    "        trash_feats.append(feature)\n",
    "for feature in numerical_features:\n",
    "    if numcoeffs[feature] < NUMTHRESHOLD or house_data[feature].value_counts(normalize=True, dropna=False).iloc[0] > 0.99:\n",
    "        trash_feats.append(feature)\n",
    "for feature in trash_feats:\n",
    "    if feature in numerical_features:\n",
    "        numerical_features.remove(feature)\n",
    "train_data = quality_preprocess(train_data)\n",
    "train_data = train_data.drop(columns = trash_feats)\n",
    "train_data = categorical_preprocess(train_data)\n",
    "\n",
    "print(f\"Removed the following features: {trash_feats}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c7d227",
   "metadata": {
    "papermill": {
     "duration": 0.004168,
     "end_time": "2022-07-24T11:50:54.809689",
     "exception": false,
     "start_time": "2022-07-24T11:50:54.805521",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Prepare the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1649d203",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T11:50:54.820068Z",
     "iopub.status.busy": "2022-07-24T11:50:54.819728Z",
     "iopub.status.idle": "2022-07-24T11:50:54.825506Z",
     "shell.execute_reply": "2022-07-24T11:50:54.824337Z"
    },
    "papermill": {
     "duration": 0.01366,
     "end_time": "2022-07-24T11:50:54.827714",
     "exception": false,
     "start_time": "2022-07-24T11:50:54.814054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "\n",
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "    opt = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "    model.compile(optimizer=opt, loss=\"mse\", metrics=[\"mae\"])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d5790e",
   "metadata": {
    "papermill": {
     "duration": 0.004156,
     "end_time": "2022-07-24T11:50:54.836359",
     "exception": false,
     "start_time": "2022-07-24T11:50:54.832203",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Set up k-fold validation and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44356d3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T11:50:54.846889Z",
     "iopub.status.busy": "2022-07-24T11:50:54.846476Z",
     "iopub.status.idle": "2022-07-24T11:51:10.551652Z",
     "shell.execute_reply": "2022-07-24T11:51:10.550574Z"
    },
    "papermill": {
     "duration": 15.71335,
     "end_time": "2022-07-24T11:51:10.554051",
     "exception": false,
     "start_time": "2022-07-24T11:50:54.840701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-24 11:50:56.237869: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2022-07-24 11:50:56.385887: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/55\n",
      "3/3 [==============================] - 1s 110ms/step - loss: 38288412672.0000 - mae: 178607.5938 - val_loss: 36333207552.0000 - val_mae: 176237.0156\n",
      "Epoch 2/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 34678050816.0000 - mae: 169961.7344 - val_loss: 33153257472.0000 - val_mae: 168345.5312\n",
      "Epoch 3/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 31663831040.0000 - mae: 162382.5781 - val_loss: 30233036800.0000 - val_mae: 160752.4375\n",
      "Epoch 4/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 28894803968.0000 - mae: 155125.4844 - val_loss: 27704954880.0000 - val_mae: 153875.2969\n",
      "Epoch 5/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 26435053568.0000 - mae: 148408.2344 - val_loss: 25333661696.0000 - val_mae: 147143.4531\n",
      "Epoch 6/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 24201748480.0000 - mae: 141969.9219 - val_loss: 23143964672.0000 - val_mae: 140640.0625\n",
      "Epoch 7/55\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 22061377536.0000 - mae: 135572.5312 - val_loss: 20961103872.0000 - val_mae: 133841.4688\n",
      "Epoch 8/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 19952730112.0000 - mae: 128911.7812 - val_loss: 18819768320.0000 - val_mae: 126817.9531\n",
      "Epoch 9/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 17868703744.0000 - mae: 122020.3047 - val_loss: 16727013376.0000 - val_mae: 119555.9141\n",
      "Epoch 10/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 15824309248.0000 - mae: 114864.9688 - val_loss: 14674112512.0000 - val_mae: 111977.0625\n",
      "Epoch 11/55\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 13873705984.0000 - mae: 107467.4609 - val_loss: 12652260352.0000 - val_mae: 103972.3516\n",
      "Epoch 12/55\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 11909985280.0000 - mae: 99582.5000 - val_loss: 10701741056.0000 - val_mae: 95619.1016\n",
      "Epoch 13/55\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 10035683328.0000 - mae: 91406.4844 - val_loss: 8855050240.0000 - val_mae: 86971.6953\n",
      "Epoch 14/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 8268540928.0000 - mae: 82922.8281 - val_loss: 7110340608.0000 - val_mae: 77926.3359\n",
      "Epoch 15/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 6602914816.0000 - mae: 74063.3828 - val_loss: 5505618944.0000 - val_mae: 68561.9609\n",
      "Epoch 16/55\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 5061644288.0000 - mae: 64878.7891 - val_loss: 4078286592.0000 - val_mae: 58997.6875\n",
      "Epoch 17/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3726447360.0000 - mae: 55571.6992 - val_loss: 2856858624.0000 - val_mae: 49365.2344\n",
      "Epoch 18/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 2562637568.0000 - mae: 46156.6875 - val_loss: 1854922496.0000 - val_mae: 39761.5078\n",
      "Epoch 19/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1646377600.0000 - mae: 36859.8516 - val_loss: 1078963456.0000 - val_mae: 30305.1641\n",
      "Epoch 20/55\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 935772928.0000 - mae: 27743.3594 - val_loss: 536730784.0000 - val_mae: 21349.1250\n",
      "Epoch 21/55\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 447071008.0000 - mae: 19144.8652 - val_loss: 205759408.0000 - val_mae: 13185.4990\n",
      "Epoch 22/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 161138720.0000 - mae: 11392.8369 - val_loss: 44151992.0000 - val_mae: 6059.9932\n",
      "Epoch 23/55\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 29274544.0000 - mae: 4661.8110 - val_loss: 126068.1094 - val_mae: 247.1707\n",
      "Epoch 24/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1725173.5000 - mae: 975.0322 - val_loss: 21055790.0000 - val_mae: 4324.7773\n",
      "Epoch 25/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 28462424.0000 - mae: 4907.0962 - val_loss: 62265344.0000 - val_mae: 7382.0796\n",
      "Epoch 26/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 67760320.0000 - mae: 7603.4238 - val_loss: 94222512.0000 - val_mae: 9062.7891\n",
      "Epoch 27/55\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 94853096.0000 - mae: 8992.1992 - val_loss: 104733848.0000 - val_mae: 9550.5908\n",
      "Epoch 28/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 101065312.0000 - mae: 9278.5674 - val_loss: 95554808.0000 - val_mae: 9126.0010\n",
      "Epoch 29/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 89057592.0000 - mae: 8715.5430 - val_loss: 73327296.0000 - val_mae: 8004.1855\n",
      "Epoch 30/55\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 66265640.0000 - mae: 7521.7192 - val_loss: 47200796.0000 - val_mae: 6437.2378\n",
      "Epoch 31/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 41335988.0000 - mae: 5954.5488 - val_loss: 25287766.0000 - val_mae: 4732.1162\n",
      "Epoch 32/55\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 21377208.0000 - mae: 4296.8594 - val_loss: 10426800.0000 - val_mae: 3064.5061\n",
      "Epoch 33/55\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 8268472.0000 - mae: 2697.2380 - val_loss: 2652079.7500 - val_mae: 1576.6875\n",
      "Epoch 34/55\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 1855060.7500 - mae: 1293.3120 - val_loss: 127955.1094 - val_mae: 344.6960\n",
      "Epoch 35/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 103718.4609 - mae: 267.4997 - val_loss: 579298.8750 - val_mae: 597.7285\n",
      "Epoch 36/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 835404.5625 - mae: 705.4188 - val_loss: 2027382.7500 - val_mae: 1218.5968\n",
      "Epoch 37/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 2238605.0000 - mae: 1252.4744 - val_loss: 3201902.7500 - val_mae: 1559.6899\n",
      "Epoch 38/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3233857.2500 - mae: 1533.7042 - val_loss: 3603814.5000 - val_mae: 1661.1594\n",
      "Epoch 39/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3481681.7500 - mae: 1595.2664 - val_loss: 3273385.5000 - val_mae: 1578.2360\n",
      "Epoch 40/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3039402.0000 - mae: 1483.8424 - val_loss: 2452805.5000 - val_mae: 1351.6531\n",
      "Epoch 41/55\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 2211510.0000 - mae: 1242.9868 - val_loss: 1509226.6250 - val_mae: 1035.6509\n",
      "Epoch 42/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1308660.0000 - mae: 928.7701 - val_loss: 755948.8750 - val_mae: 697.9894\n",
      "Epoch 43/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 641952.0000 - mae: 605.4501 - val_loss: 281600.6562 - val_mae: 389.8630\n",
      "Epoch 44/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 227193.2500 - mae: 320.6856 - val_loss: 78467.2031 - val_mae: 201.2815\n",
      "Epoch 45/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 72456.5469 - mae: 189.9249 - val_loss: 54337.4141 - val_mae: 205.6053\n",
      "Epoch 46/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 70082.3672 - mae: 237.4735 - val_loss: 111824.6484 - val_mae: 318.4339\n",
      "Epoch 47/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 131628.7344 - mae: 350.5688 - val_loss: 173947.1719 - val_mae: 411.2298\n",
      "Epoch 48/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 186478.4531 - mae: 426.3558 - val_loss: 201490.0312 - val_mae: 445.4344\n",
      "Epoch 49/55\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 205333.9375 - mae: 449.2252 - val_loss: 189551.1875 - val_mae: 431.0364\n",
      "Epoch 50/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 187722.3594 - mae: 427.9947 - val_loss: 152355.7500 - val_mae: 381.7389\n",
      "Epoch 51/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 149296.4219 - mae: 376.7401 - val_loss: 109503.3984 - val_mae: 314.5960\n",
      "Epoch 52/55\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 108500.3594 - mae: 313.1388 - val_loss: 75183.7266 - val_mae: 251.3393\n",
      "Epoch 53/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 77919.4844 - mae: 256.2729 - val_loss: 55353.8633 - val_mae: 208.3817\n",
      "Epoch 54/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 60828.9219 - mae: 215.0042 - val_loss: 48596.3008 - val_mae: 187.1248\n",
      "Epoch 55/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 56345.1641 - mae: 193.2353 - val_loss: 49708.5039 - val_mae: 180.3007\n",
      "Epoch 1/55\n",
      "3/3 [==============================] - 1s 93ms/step - loss: 38208421888.0000 - mae: 179927.5938 - val_loss: 37252927488.0000 - val_mae: 174022.5156\n",
      "Epoch 2/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 34698186752.0000 - mae: 171465.0625 - val_loss: 33799327744.0000 - val_mae: 165757.0156\n",
      "Epoch 3/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 31456602112.0000 - mae: 163249.4531 - val_loss: 30613057536.0000 - val_mae: 157754.4844\n",
      "Epoch 4/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 28530311168.0000 - mae: 155500.9375 - val_loss: 27974780928.0000 - val_mae: 150800.6719\n",
      "Epoch 5/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 26095296512.0000 - mae: 148658.5000 - val_loss: 25448230912.0000 - val_mae: 143827.1406\n",
      "Epoch 6/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 23693281280.0000 - mae: 141661.2969 - val_loss: 22994024448.0000 - val_mae: 136706.2500\n",
      "Epoch 7/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 21380370432.0000 - mae: 134590.8281 - val_loss: 20669562880.0000 - val_mae: 129608.3750\n",
      "Epoch 8/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 19182852096.0000 - mae: 127489.6250 - val_loss: 18385045504.0000 - val_mae: 122234.3125\n",
      "Epoch 9/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 17052358656.0000 - mae: 120155.6406 - val_loss: 16242587648.0000 - val_mae: 114888.2188\n",
      "Epoch 10/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 15015130112.0000 - mae: 112789.0781 - val_loss: 14150575104.0000 - val_mae: 107228.5234\n",
      "Epoch 11/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 13039396864.0000 - mae: 105077.5859 - val_loss: 12108271616.0000 - val_mae: 99182.0312\n",
      "Epoch 12/55\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 11129016320.0000 - mae: 97049.7812 - val_loss: 10165755904.0000 - val_mae: 90869.4609\n",
      "Epoch 13/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 9285329920.0000 - mae: 88700.1094 - val_loss: 8336569344.0000 - val_mae: 82278.9531\n",
      "Epoch 14/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 7566117376.0000 - mae: 80072.4688 - val_loss: 6627872768.0000 - val_mae: 73352.0078\n",
      "Epoch 15/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 5978076160.0000 - mae: 71136.3125 - val_loss: 5080314880.0000 - val_mae: 64205.9883\n",
      "Epoch 16/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 4551731712.0000 - mae: 62023.1953 - val_loss: 3720151552.0000 - val_mae: 54926.1875\n",
      "Epoch 17/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3301920512.0000 - mae: 52795.5078 - val_loss: 2565341440.0000 - val_mae: 45591.3711\n",
      "Epoch 18/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2241339648.0000 - mae: 43510.2422 - val_loss: 1640387456.0000 - val_mae: 36433.4102\n",
      "Epoch 19/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1409256320.0000 - mae: 34455.0000 - val_loss: 943902336.0000 - val_mae: 27607.9434\n",
      "Epoch 20/55\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 794480896.0000 - mae: 25802.6172 - val_loss: 471404800.0000 - val_mae: 19473.8535\n",
      "Epoch 21/55\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 386319456.0000 - mae: 17900.6777 - val_loss: 185928464.0000 - val_mae: 12183.6670\n",
      "Epoch 22/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 142870448.0000 - mae: 10810.6279 - val_loss: 44287544.0000 - val_mae: 5880.4512\n",
      "Epoch 23/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 28628130.0000 - mae: 4734.5806 - val_loss: 880739.0000 - val_mae: 703.1083\n",
      "Epoch 24/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 970329.3750 - mae: 821.0808 - val_loss: 12520026.0000 - val_mae: 3304.3433\n",
      "Epoch 25/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 17667296.0000 - mae: 3914.8904 - val_loss: 43619164.0000 - val_mae: 6076.4316\n",
      "Epoch 26/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 47276660.0000 - mae: 6425.5708 - val_loss: 70752240.0000 - val_mae: 7708.4951\n",
      "Epoch 27/55\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 71021464.0000 - mae: 7855.3496 - val_loss: 83389800.0000 - val_mae: 8358.9727\n",
      "Epoch 28/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 79925264.0000 - mae: 8331.2461 - val_loss: 80250928.0000 - val_mae: 8202.2188\n",
      "Epoch 29/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 74379272.0000 - mae: 8040.6621 - val_loss: 65653292.0000 - val_mae: 7429.4575\n",
      "Epoch 30/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 59240236.0000 - mae: 7179.4829 - val_loss: 46246160.0000 - val_mae: 6253.1807\n",
      "Epoch 31/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 40590792.0000 - mae: 5959.9819 - val_loss: 28024052.0000 - val_mae: 4891.7197\n",
      "Epoch 32/55\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 23995566.0000 - mae: 4591.9883 - val_loss: 14010085.0000 - val_mae: 3489.1870\n",
      "Epoch 33/55\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 11458308.0000 - mae: 3203.6421 - val_loss: 5290158.5000 - val_mae: 2180.7881\n",
      "Epoch 34/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 4117805.0000 - mae: 1935.9955 - val_loss: 1117251.0000 - val_mae: 1040.2992\n",
      "Epoch 35/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 761214.6250 - mae: 841.8315 - val_loss: 77766.4609 - val_mae: 233.4873\n",
      "Epoch 36/55\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 111384.7891 - mae: 234.0061 - val_loss: 647800.7500 - val_mae: 584.3218\n",
      "Epoch 37/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 747656.3125 - mae: 666.8636 - val_loss: 1638068.2500 - val_mae: 1014.5500\n",
      "Epoch 38/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1638172.0000 - mae: 1059.8969 - val_loss: 2358053.2500 - val_mae: 1246.7887\n",
      "Epoch 39/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2217136.7500 - mae: 1256.4546 - val_loss: 2565685.2500 - val_mae: 1307.0596\n",
      "Epoch 40/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 2317885.2500 - mae: 1287.3827 - val_loss: 2304508.2500 - val_mae: 1230.9258\n",
      "Epoch 41/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2008577.1250 - mae: 1189.0428 - val_loss: 1757834.0000 - val_mae: 1056.4124\n",
      "Epoch 42/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1481939.0000 - mae: 1000.6001 - val_loss: 1150248.2500 - val_mae: 825.6263\n",
      "Epoch 43/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 933557.0000 - mae: 763.9474 - val_loss: 645947.9375 - val_mae: 583.4825\n",
      "Epoch 44/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 495595.5312 - mae: 522.7684 - val_loss: 310543.9688 - val_mae: 370.4947\n",
      "Epoch 45/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 218668.6406 - mae: 317.4329 - val_loss: 134667.3906 - val_mae: 245.9596\n",
      "Epoch 46/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 89915.0547 - mae: 206.3820 - val_loss: 78764.9844 - val_mae: 226.5250\n",
      "Epoch 47/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 64170.3242 - mae: 209.4607 - val_loss: 90509.2969 - val_mae: 271.5031\n",
      "Epoch 48/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 89164.2266 - mae: 272.5502 - val_loss: 122199.6094 - val_mae: 325.7245\n",
      "Epoch 49/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 123446.0469 - mae: 333.0854 - val_loss: 144978.3750 - val_mae: 360.8343\n",
      "Epoch 50/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 143491.5156 - mae: 364.0598 - val_loss: 148109.7031 - val_mae: 365.5892\n",
      "Epoch 51/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 142870.7188 - mae: 363.2279 - val_loss: 134927.1562 - val_mae: 345.6122\n",
      "Epoch 52/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 126927.2969 - mae: 338.6986 - val_loss: 114687.5703 - val_mae: 313.6139\n",
      "Epoch 53/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 105082.7578 - mae: 302.1757 - val_loss: 96055.6484 - val_mae: 282.2633\n",
      "Epoch 54/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 85185.0703 - mae: 264.9377 - val_loss: 83472.8359 - val_mae: 256.4829\n",
      "Epoch 55/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 71470.5625 - mae: 234.4538 - val_loss: 77749.0234 - val_mae: 239.0980\n",
      "Epoch 1/55\n",
      "3/3 [==============================] - 1s 94ms/step - loss: 34910101504.0000 - mae: 170768.1094 - val_loss: 29622331392.0000 - val_mae: 158549.1094\n",
      "Epoch 2/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 30671110144.0000 - mae: 160103.7812 - val_loss: 26189592576.0000 - val_mae: 149075.7969\n",
      "Epoch 3/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 27211995136.0000 - mae: 150747.2812 - val_loss: 23374538752.0000 - val_mae: 140831.1406\n",
      "Epoch 4/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 24271925248.0000 - mae: 142345.6094 - val_loss: 20668000256.0000 - val_mae: 132422.7656\n",
      "Epoch 5/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 21417238528.0000 - mae: 133687.6719 - val_loss: 18116767744.0000 - val_mae: 123975.0703\n",
      "Epoch 6/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 18736478208.0000 - mae: 125095.1172 - val_loss: 15748278272.0000 - val_mae: 115584.5391\n",
      "Epoch 7/55\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 16257325056.0000 - mae: 116437.3672 - val_loss: 13434244096.0000 - val_mae: 106760.1016\n",
      "Epoch 8/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 13816812544.0000 - mae: 107396.6016 - val_loss: 11287951360.0000 - val_mae: 97854.6094\n",
      "Epoch 9/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 11544536064.0000 - mae: 98163.3750 - val_loss: 9214543872.0000 - val_mae: 88406.4219\n",
      "Epoch 10/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 9374067712.0000 - mae: 88425.1953 - val_loss: 7258708480.0000 - val_mae: 78454.6719\n",
      "Epoch 11/55\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 7314248192.0000 - mae: 78124.0469 - val_loss: 5449066496.0000 - val_mae: 67963.1875\n",
      "Epoch 12/55\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 5439512064.0000 - mae: 67311.3906 - val_loss: 3844253184.0000 - val_mae: 57069.7656\n",
      "Epoch 13/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3764024576.0000 - mae: 56054.5391 - val_loss: 2485789184.0000 - val_mae: 45872.9727\n",
      "Epoch 14/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2407022080.0000 - mae: 44635.3359 - val_loss: 1415651200.0000 - val_mae: 34594.4453\n",
      "Epoch 15/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1322028160.0000 - mae: 33113.9922 - val_loss: 663831360.0000 - val_mae: 23658.7266\n",
      "Epoch 16/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 585157120.0000 - mae: 22021.5898 - val_loss: 215332032.0000 - val_mae: 13431.7480\n",
      "Epoch 17/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 170627952.0000 - mae: 11751.1367 - val_loss: 23202614.0000 - val_mae: 4338.7217\n",
      "Epoch 18/55\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 13557654.0000 - mae: 2943.6543 - val_loss: 10828935.0000 - val_mae: 3122.3242\n",
      "Epoch 19/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 24051722.0000 - mae: 4416.3691 - val_loss: 84217640.0000 - val_mae: 8555.5518\n",
      "Epoch 20/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 106412720.0000 - mae: 9512.4414 - val_loss: 160912848.0000 - val_mae: 11791.1494\n",
      "Epoch 21/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 180764592.0000 - mae: 12396.6084 - val_loss: 194428080.0000 - val_mae: 12951.7891\n",
      "Epoch 22/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 204931136.0000 - mae: 13198.9287 - val_loss: 177577088.0000 - val_mae: 12381.7578\n",
      "Epoch 23/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 179414784.0000 - mae: 12345.5283 - val_loss: 130389640.0000 - val_mae: 10622.8311\n",
      "Epoch 24/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 126056624.0000 - mae: 10376.4326 - val_loss: 77314808.0000 - val_mae: 8200.5576\n",
      "Epoch 25/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 71988904.0000 - mae: 7828.6084 - val_loss: 34560700.0000 - val_mae: 5511.7998\n",
      "Epoch 26/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 30274120.0000 - mae: 5091.4258 - val_loss: 9723498.0000 - val_mae: 2961.9119\n",
      "Epoch 27/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 7470820.5000 - mae: 2544.5200 - val_loss: 621163.6875 - val_mae: 785.6932\n",
      "Epoch 28/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 344951.4688 - mae: 504.1272 - val_loss: 1209397.8750 - val_mae: 897.3446\n",
      "Epoch 29/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2201601.7500 - mae: 1196.7306 - val_loss: 5306431.0000 - val_mae: 2017.3594\n",
      "Epoch 30/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 6597624.5000 - mae: 2228.0261 - val_loss: 8619904.0000 - val_mae: 2602.3574\n",
      "Epoch 31/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 9630834.0000 - mae: 2726.2312 - val_loss: 9500332.0000 - val_mae: 2737.7571\n",
      "Epoch 32/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 10064871.0000 - mae: 2790.7395 - val_loss: 8114057.0000 - val_mae: 2521.5159\n",
      "Epoch 33/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 8189580.0000 - mae: 2504.5029 - val_loss: 5395906.0000 - val_mae: 2035.4476\n",
      "Epoch 34/55\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 5236733.5000 - mae: 1973.9979 - val_loss: 2727791.7500 - val_mae: 1412.9795\n",
      "Epoch 35/55\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 2529067.2500 - mae: 1324.6030 - val_loss: 912835.9375 - val_mae: 761.8027\n",
      "Epoch 36/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 795632.1875 - mae: 673.6924 - val_loss: 141312.4844 - val_mae: 242.0810\n",
      "Epoch 37/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 119325.4531 - mae: 237.1780 - val_loss: 111382.6172 - val_mae: 316.0425\n",
      "Epoch 38/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 157469.9062 - mae: 376.5019 - val_loss: 393670.3125 - val_mae: 627.4185\n",
      "Epoch 39/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 451774.5625 - mae: 670.4221 - val_loss: 647236.6250 - val_mae: 801.4564\n",
      "Epoch 40/55\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 680995.6250 - mae: 820.9185 - val_loss: 715952.0625 - val_mae: 841.6567\n",
      "Epoch 41/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 710172.2500 - mae: 837.8127 - val_loss: 602220.4375 - val_mae: 773.8115\n",
      "Epoch 42/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 569231.3125 - mae: 751.9952 - val_loss: 403884.7188 - val_mae: 635.5138\n",
      "Epoch 43/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 363496.3438 - mae: 601.6094 - val_loss: 219121.2969 - val_mae: 462.5475\n",
      "Epoch 44/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 188745.0625 - mae: 423.8105 - val_loss: 103677.7344 - val_mae: 302.6967\n",
      "Epoch 45/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 91576.5469 - mae: 275.7789 - val_loss: 61900.0156 - val_mae: 206.6470\n",
      "Epoch 46/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 66622.5938 - mae: 211.7085 - val_loss: 66679.8828 - val_mae: 182.8592\n",
      "Epoch 47/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 81762.1328 - mae: 206.8989 - val_loss: 85049.6719 - val_mae: 191.8703\n",
      "Epoch 48/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 103089.2344 - mae: 220.8611 - val_loss: 96112.7031 - val_mae: 200.7058\n",
      "Epoch 49/55\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 113188.2969 - mae: 228.1209 - val_loss: 93122.9453 - val_mae: 198.1106\n",
      "Epoch 50/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 106460.4531 - mae: 222.9955 - val_loss: 80593.1562 - val_mae: 188.5958\n",
      "Epoch 51/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 90611.8047 - mae: 211.2860 - val_loss: 68107.8047 - val_mae: 182.5472\n",
      "Epoch 52/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 75974.6172 - mae: 203.5713 - val_loss: 61083.5000 - val_mae: 186.5234\n",
      "Epoch 53/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 67119.7891 - mae: 203.7035 - val_loss: 59909.6289 - val_mae: 197.1734\n",
      "Epoch 54/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 64805.4141 - mae: 210.3363 - val_loss: 62528.7617 - val_mae: 209.8642\n",
      "Epoch 55/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 66534.2812 - mae: 219.9183 - val_loss: 65641.9531 - val_mae: 219.9135\n",
      "Epoch 1/55\n",
      "3/3 [==============================] - 1s 118ms/step - loss: 41364815872.0000 - mae: 186176.7344 - val_loss: 37985808384.0000 - val_mae: 178528.1250\n",
      "Epoch 2/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 38264250368.0000 - mae: 179061.0625 - val_loss: 35447615488.0000 - val_mae: 172453.7344\n",
      "Epoch 3/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 35863982080.0000 - mae: 173309.7031 - val_loss: 33500889088.0000 - val_mae: 167644.5000\n",
      "Epoch 4/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 33861517312.0000 - mae: 168443.7500 - val_loss: 31665481728.0000 - val_mae: 162984.9531\n",
      "Epoch 5/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 31996590080.0000 - mae: 163723.1562 - val_loss: 29819830272.0000 - val_mae: 158159.3438\n",
      "Epoch 6/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 30112880640.0000 - mae: 158834.3281 - val_loss: 28022781952.0000 - val_mae: 153312.5781\n",
      "Epoch 7/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 28273645568.0000 - mae: 153906.5781 - val_loss: 26222839808.0000 - val_mae: 148300.7188\n",
      "Epoch 8/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 26442196992.0000 - mae: 148801.0938 - val_loss: 24369528832.0000 - val_mae: 142958.2812\n",
      "Epoch 9/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 24529393664.0000 - mae: 143338.2969 - val_loss: 22481537024.0000 - val_mae: 137301.5156\n",
      "Epoch 10/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 22591012864.0000 - mae: 137558.6406 - val_loss: 20638527488.0000 - val_mae: 131553.1250\n",
      "Epoch 11/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 20712835072.0000 - mae: 131716.4844 - val_loss: 18776295424.0000 - val_mae: 125468.7891\n",
      "Epoch 12/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 18795468800.0000 - mae: 125472.9922 - val_loss: 16870028288.0000 - val_mae: 118919.1328\n",
      "Epoch 13/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 16850972672.0000 - mae: 118752.0781 - val_loss: 14868429824.0000 - val_mae: 111637.4141\n",
      "Epoch 14/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 14791826432.0000 - mae: 111254.9688 - val_loss: 12832216064.0000 - val_mae: 103697.8984\n",
      "Epoch 15/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 12694744064.0000 - mae: 103083.0156 - val_loss: 10811504640.0000 - val_mae: 95167.4297\n",
      "Epoch 16/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 10651464704.0000 - mae: 94360.9141 - val_loss: 8843677696.0000 - val_mae: 86052.9531\n",
      "Epoch 17/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 8659384320.0000 - mae: 85085.6641 - val_loss: 7018481664.0000 - val_mae: 76638.6172\n",
      "Epoch 18/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 6820760064.0000 - mae: 75501.9219 - val_loss: 5352565248.0000 - val_mae: 66900.9141\n",
      "Epoch 19/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 5138654720.0000 - mae: 65556.6953 - val_loss: 3884691200.0000 - val_mae: 56962.9375\n",
      "Epoch 20/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3701345024.0000 - mae: 55546.7891 - val_loss: 2633091840.0000 - val_mae: 46860.0117\n",
      "Epoch 21/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2462838784.0000 - mae: 45296.1094 - val_loss: 1646083712.0000 - val_mae: 37012.2188\n",
      "Epoch 22/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1527166208.0000 - mae: 35511.6328 - val_loss: 921003648.0000 - val_mae: 27632.8652\n",
      "Epoch 23/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 827754176.0000 - mae: 26120.8965 - val_loss: 433539584.0000 - val_mae: 18892.3945\n",
      "Epoch 24/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 375091168.0000 - mae: 17459.1953 - val_loss: 149527024.0000 - val_mae: 11005.4395\n",
      "Epoch 25/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 119411456.0000 - mae: 9688.7227 - val_loss: 23644092.0000 - val_mae: 4234.0840\n",
      "Epoch 26/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 15299721.0000 - mae: 3136.3210 - val_loss: 1526300.2500 - val_mae: 1235.3048\n",
      "Epoch 27/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 5775187.0000 - mae: 2152.5227 - val_loss: 31056742.0000 - val_mae: 5292.9736\n",
      "Epoch 28/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 40084092.0000 - mae: 5954.7144 - val_loss: 71301600.0000 - val_mae: 7934.0220\n",
      "Epoch 29/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 79259016.0000 - mae: 8341.0342 - val_loss: 97887272.0000 - val_mae: 9265.9824\n",
      "Epoch 30/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 102267336.0000 - mae: 9460.3174 - val_loss: 103316584.0000 - val_mae: 9514.5625\n",
      "Epoch 31/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 103573968.0000 - mae: 9519.7588 - val_loss: 90243488.0000 - val_mae: 8903.8428\n",
      "Epoch 32/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 87494952.0000 - mae: 8768.3750 - val_loss: 67129952.0000 - val_mae: 7703.4316\n",
      "Epoch 33/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 62994304.0000 - mae: 7462.9575 - val_loss: 42239176.0000 - val_mae: 6145.5547\n",
      "Epoch 34/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 38564560.0000 - mae: 5863.5396 - val_loss: 21998392.0000 - val_mae: 4479.0938\n",
      "Epoch 35/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 19167882.0000 - mae: 4178.9272 - val_loss: 8749577.0000 - val_mae: 2875.0586\n",
      "Epoch 36/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 7181872.5000 - mae: 2593.3174 - val_loss: 2114313.0000 - val_mae: 1451.9702\n",
      "Epoch 37/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1540786.7500 - mae: 1211.9978 - val_loss: 266848.2188 - val_mae: 435.3297\n",
      "Epoch 38/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 335898.4688 - mae: 438.4424 - val_loss: 951175.6250 - val_mae: 645.0679\n",
      "Epoch 39/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1271084.3750 - mae: 787.1255 - val_loss: 2337240.0000 - val_mae: 1145.6998\n",
      "Epoch 40/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2668688.7500 - mae: 1244.0370 - val_loss: 3334658.7500 - val_mae: 1421.9296\n",
      "Epoch 41/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3530924.0000 - mae: 1472.2385 - val_loss: 3564383.0000 - val_mae: 1479.4048\n",
      "Epoch 42/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3637945.7500 - mae: 1497.9861 - val_loss: 3145255.7500 - val_mae: 1373.3214\n",
      "Epoch 43/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3087992.0000 - mae: 1360.8502 - val_loss: 2318036.0000 - val_mae: 1140.1462\n",
      "Epoch 44/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2217021.5000 - mae: 1114.8702 - val_loss: 1464226.2500 - val_mae: 851.6362\n",
      "Epoch 45/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1377658.5000 - mae: 828.1187 - val_loss: 806139.4375 - val_mae: 583.7006\n",
      "Epoch 46/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 739420.5000 - mae: 574.3666 - val_loss: 422530.9375 - val_mae: 427.9547\n",
      "Epoch 47/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 392157.2812 - mae: 429.6209 - val_loss: 269171.9375 - val_mae: 387.8232\n",
      "Epoch 48/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 272022.3750 - mae: 408.3675 - val_loss: 267319.8750 - val_mae: 437.6587\n",
      "Epoch 49/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 275778.7500 - mae: 457.0329 - val_loss: 326187.4062 - val_mae: 511.5023\n",
      "Epoch 50/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 334091.5625 - mae: 524.2894 - val_loss: 381197.9375 - val_mae: 569.3818\n",
      "Epoch 51/55\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 382182.2812 - mae: 569.5359 - val_loss: 402892.7188 - val_mae: 590.1581\n",
      "Epoch 52/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 396184.6875 - mae: 582.5480 - val_loss: 390086.8438 - val_mae: 578.1017\n",
      "Epoch 53/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 378156.3438 - mae: 566.5813 - val_loss: 355830.1875 - val_mae: 543.7888\n",
      "Epoch 54/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 342343.5625 - mae: 533.1774 - val_loss: 315896.5938 - val_mae: 500.5687\n",
      "Epoch 55/55\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 305224.8125 - mae: 494.2052 - val_loss: 283337.1562 - val_mae: 462.2114\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "EPOCHS = 55\n",
    "FOLDS = 4\n",
    "FOLD_SIZE = len(train_data) // FOLDS\n",
    "val_accs = []\n",
    "total_val_acc = []\n",
    "train_accs = []\n",
    "total_train_acc = []\n",
    "for k in range(FOLDS):    \n",
    "    val_data = train_data.iloc[k * FOLD_SIZE: (k+1) * FOLD_SIZE]\n",
    "    val_labels = train_labels.iloc[k * FOLD_SIZE: (k+1) * FOLD_SIZE]\n",
    "    partial_train_data = pd.concat([train_data.iloc[: k * FOLD_SIZE] , train_data.iloc[(k+1) * FOLD_SIZE :]])\n",
    "    partial_train_labels = pd.concat([train_labels.iloc[: k * FOLD_SIZE] , train_labels.iloc[(k+1) * FOLD_SIZE :]])\n",
    "    val_data = normalise_preprocess(val_data.copy())\n",
    "    partial_train_data = normalise_preprocess(partial_train_data.copy())\n",
    "    \n",
    "    assert pd.merge(partial_train_data, val_data, how='inner').shape[0] == 0     # sanity check to ensure no samples shared between validation set and training set\n",
    "\n",
    "    model = build_model()\n",
    "\n",
    "    history = model.fit(partial_train_data,\n",
    "                        partial_train_labels,\n",
    "                        epochs=EPOCHS,\n",
    "                        batch_size=512,\n",
    "                        validation_data=(val_data, val_labels),\n",
    "                        verbose=1,\n",
    "                        )\n",
    "\n",
    "    history_dict = history.history\n",
    "\n",
    "    train_accs.append(history_dict['mae'])\n",
    "    val_accs.append(history_dict['val_mae'])\n",
    "\n",
    "for e in range(len(val_accs[0])):\n",
    "        valsum = 0\n",
    "        trainsum = 0\n",
    "        for k in range(FOLDS):\n",
    "            valsum += val_accs[k][e]\n",
    "            trainsum += train_accs[k][e]\n",
    "        total_val = valsum / FOLDS\n",
    "        total_train = trainsum / FOLDS\n",
    "        total_val_acc.append(total_val)\n",
    "        total_train_acc.append(total_train)\n",
    "        \n",
    "        \n",
    "epochs = range(1, len(total_train_acc) + 1)\n",
    "\n",
    "plt.plot(epochs, total_train_acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, total_val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 37.448024,
   "end_time": "2022-07-24T11:51:13.638461",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-07-24T11:50:36.190437",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
